{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbvvDsh3Ud6INLy6PjnZ7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-ML-Zoomcamp-Week-4/blob/main/ML_Zoomcamp_Week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goldsmiths University of London\n",
        "**Author....: Carlos Manuel de Oliveira Alves**<br>\n",
        "**Student..: cdeol003**<br>\n",
        "**Created..: 27/09/2022**"
      ],
      "metadata": {
        "id": "6gEcamMvoqD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sERKxvvdomPg"
      },
      "outputs": [],
      "source": [
        "# Import libraries for the project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import the library warnings to ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets train the model again first - to use its results later in this notebook\n",
        "\n",
        "# Import packages from Sklearn for the project\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "NU5InPEkuw-d"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data import and preparation\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in string_columns:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "df.churn = (df.churn == 'yes').astype(int)"
      ],
      "metadata": {
        "id": "DwZLJNAjvYjo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the validation framework\n",
        "\n",
        "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
        "\n",
        "y_train = df_train.churn.values\n",
        "y_val = df_val.churn.values\n",
        "\n",
        "del df_train['churn']\n",
        "del df_val['churn']"
      ],
      "metadata": {
        "id": "_QfstrMiwCsY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of categorical and numerical variables\n",
        "\n",
        "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "               'phoneservice', 'multiplelines', 'internetservice',\n",
        "               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
        "               'techsupport', 'streamingtv', 'streamingmovies',\n",
        "               'contract', 'paperlessbilling', 'paymentmethod']\n",
        "\n",
        "numerical = ['tenure', 'monthlycharges', 'totalcharges']"
      ],
      "metadata": {
        "id": "Jhf2i3E5wTeO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv.fit(train_dict)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_train = dv.transform(train_dict)"
      ],
      "metadata": {
        "id": "s_T7YeKBwiPO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model logistic regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# For training the model we use the fit method\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hfgdUOuxggk",
        "outputId": "2b72f69e-111c-4b62-c258-169dee9250f0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create validation dictionary with categorical and numerical variables\n",
        "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our validation dictionary\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "# Apply our model on X validation and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]"
      ],
      "metadata": {
        "id": "n_VWjZV4yTkK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small subset from the dataframe\n",
        "small_subset = ['contract', 'tenure', 'totalcharges']\n",
        "\n",
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict_small = df_train[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv_small = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv_small.fit(train_dict_small)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_train = dv_small.transform(train_dict_small)\n",
        "\n",
        "# Create a model logistic regression\n",
        "model_small = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "model_small.fit(X_small_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQPuMETzwkJ",
        "outputId": "3550803b-8099-4563-8466-da08a559b6d2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "val_dict_small = df_val[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_val = dv_small.transform(val_dict_small)\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred_small = model_small.predict_proba(X_small_val)[:, 1]"
      ],
      "metadata": {
        "id": "eDPSjIaXH7NA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy:\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Store the Y prediction has 50% or more\n",
        "churn = y_pred >= 0.5\n",
        "\n",
        "# Calculate the percentange of the churn using the mean function\n",
        "(churn == y_val).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtUr8FW8IqD2",
        "outputId": "04e7ebed-8692-4cd2-ccef-5a564409507f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8016129032258065"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy and dummy model:\n",
        "\n",
        "# . Evaluate the model on different thresholds\n",
        "# . Check the accuracy of dummy baselines\n",
        "\n",
        "# Check how many customers we have with Y validation dataset\n",
        "len(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJzIUEz6JuGw",
        "outputId": "78604849-7612-4692-88e3-8bd2b96b4630"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1860"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 1.860 customers and for all this customers we will make a prediction\n",
        "# each customer we assign a score and then we make a decision\n",
        "# some of this decisions are correct and some of this decisions are incorrect\n",
        "\n",
        "# Check how many decisions are correct\n",
        "(y_val == churn).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl5KmgmmKk70",
        "outputId": "ebd105bc-3df9-48a9-a999-8b037f54f78b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1491"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so have 1.491 customers with the correct decision\n",
        "\n",
        "# some of our decisions are not correct and we calculate doing:\n",
        "# total of correct decisions or predictions divide by the total of customers\n",
        "# in our case is 80%"
      ],
      "metadata": {
        "id": "6BDALL1AL9oT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(round((1491 / 1860) * 100)) + '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9YU7rHhM7jL",
        "outputId": "070b6d72-3ccb-4762-bc70-d246f89bf2b5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function linspace to generate numbers from 0 to 1 with size of the array 21 elements\n",
        "thresholds = np.linspace(0, 1, 21)\n",
        "thresholds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zG7UbDJNM4d",
        "outputId": "2c1c4906-0630-4b8e-c91a-b9e943655da6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store all the accuracies\n",
        "scores = []\n",
        "\n",
        "# For eah of the values above we can treat as a threshold\n",
        "for t in thresholds:\n",
        "\n",
        "  # Store the Y prediction we use t threshold list intead of has 50% or more\n",
        "  # churn = y_pred >= 0.5 <-- THIS LINE OF CODE IT WAS BEFORE\n",
        "  # NEW LINE OF CODE:\n",
        "  churn_decision = (y_pred >= t)\n",
        "\n",
        "  # Check how many decisions are correct\n",
        "  score = (y_val == churn_decision).mean()\n",
        "\n",
        "  # Print the score with some formatation\n",
        "  print('%.2f %.3f' % (t,score))\n",
        "\n",
        "  # Append the list scores with accuracy\n",
        "  scores.append(score)\n",
        "\n",
        "  # below the 0.50 its the best threshold for this specif problem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIUJj47VNzAZ",
        "outputId": "4b510d62-5ede-4a10-f028-27bed4c25d77"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00 0.261\n",
            "0.05 0.501\n",
            "0.10 0.595\n",
            "0.15 0.640\n",
            "0.20 0.690\n",
            "0.25 0.730\n",
            "0.30 0.755\n",
            "0.35 0.767\n",
            "0.40 0.782\n",
            "0.45 0.795\n",
            "0.50 0.802\n",
            "0.55 0.790\n",
            "0.60 0.790\n",
            "0.65 0.788\n",
            "0.70 0.774\n",
            "0.75 0.752\n",
            "0.80 0.742\n",
            "0.85 0.739\n",
            "0.90 0.739\n",
            "0.95 0.739\n",
            "1.00 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the list scores with accuracies\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0iq-FlDQXhX",
        "outputId": "e9cc3a13-3fce-4bcb-bb17-27a9e1800a74"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26129032258064516,\n",
              " 0.5010752688172043,\n",
              " 0.5946236559139785,\n",
              " 0.6403225806451613,\n",
              " 0.6897849462365592,\n",
              " 0.7295698924731183,\n",
              " 0.7548387096774194,\n",
              " 0.7672043010752688,\n",
              " 0.7817204301075269,\n",
              " 0.7951612903225806,\n",
              " 0.8016129032258065,\n",
              " 0.7903225806451613,\n",
              " 0.7897849462365591,\n",
              " 0.7881720430107527,\n",
              " 0.7736559139784946,\n",
              " 0.7521505376344086,\n",
              " 0.7419354838709677,\n",
              " 0.7387096774193549,\n",
              " 0.7387096774193549,\n",
              " 0.7387096774193549,\n",
              " 0.7387096774193549]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the list scores with accuracies\n",
        "plt.plot(thresholds, scores) \n",
        "# x-axis is the thresholds\n",
        "# y-axis is the scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hwbPmLeLQwa-",
        "outputId": "784c1182-e086-45d7-bf21-e1359fe408e1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f24b2071690>]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doing the same above but now with sklearn:\n",
        "\n",
        "# Import the package accuracy score from sklearn\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Q4vFDX2nRKLG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function accuracy score from sklearn\n",
        "accuracy_score(y_val, churn_decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtOxGngSneL",
        "outputId": "c430eb54-9b53-45e6-d798-3119bbbaa622"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7387096774193549"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function accuracy score from sklearn with the threshold list\n",
        "\n",
        "# Use the function linspace to generate numbers from 0 to 1 with size of the array 21 elements\n",
        "thresholds = np.linspace(0, 1, 21)\n",
        "\n",
        "# Create a list to store all the accuracies\n",
        "scores = []\n",
        "\n",
        "# For eah of the values above we can treat as a threshold\n",
        "for t in thresholds:\n",
        "\n",
        "  # Store the result of the functin accuracy score\n",
        "  score = accuracy_score(y_val, y_pred >= t)\n",
        "\n",
        "  # Print the score with some formatation\n",
        "  print('%.2f %.3f' % (t,score))\n",
        "\n",
        "  # Append the list scores with accuracy\n",
        "  scores.append(score)\n",
        "\n",
        "# we can see below the values are exactly the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICL2pEHwS2sV",
        "outputId": "abb1ba46-8b86-4ea8-9973-70bb68bdf60d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00 0.261\n",
            "0.05 0.501\n",
            "0.10 0.595\n",
            "0.15 0.640\n",
            "0.20 0.690\n",
            "0.25 0.730\n",
            "0.30 0.755\n",
            "0.35 0.767\n",
            "0.40 0.782\n",
            "0.45 0.795\n",
            "0.50 0.802\n",
            "0.55 0.790\n",
            "0.60 0.790\n",
            "0.65 0.788\n",
            "0.70 0.774\n",
            "0.75 0.752\n",
            "0.80 0.742\n",
            "0.85 0.739\n",
            "0.90 0.739\n",
            "0.95 0.739\n",
            "1.00 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from the plot above we can see for the threshold above of 1.0\n",
        "# we don't have more values the last score is 0.739 or 73.9% this accuracy its pretty decent\n",
        "# remember our model was 80% accurate  \n",
        "# but now with our dummy model is 73.9% where predicts how many customers are not churning\n",
        "\n",
        "# Use a special package collections from Python to count things\n",
        "from collections import Counter\n",
        "\n",
        "# Use the function counter from collections to count how many are true or false\n",
        "# the line below it predicts how many customers are not churning\n",
        "Counter(y_pred >= 1.0)\n",
        "\n",
        "# below we can see the counter only count false values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4JcwQzX-5G",
        "outputId": "cbb14a38-87ab-45b0-8997-8c7fe7f68576"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({False: 1860})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion table:\n",
        "\n",
        "# . Different types of errors and correct decisions\n",
        "# . Arranging them in a table\n",
        "\n",
        "# Create an array for customers are really churn and this is for case validations are 1\n",
        "actual_positive = (y_val == 1)\n",
        "\n",
        "# Create an array for customers are not going to churn and this is for case validations are 0\n",
        "actual_negative = (y_val == 0)\n",
        "\n",
        "# the arrays above they will store true's and falses values\n",
        "actual_positive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPSo2Ok3ZBgB",
        "outputId": "e9a7f4ed-6a15-4ccd-9400-e2d681c0e9e3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the threshold for positive and negative scores\n",
        "t = 0.5\n",
        "\n",
        "# Store the positive predictions\n",
        "predict_positive = (y_pred >= t)\n",
        "\n",
        "# Store the negative predictions\n",
        "predict_negative = (y_pred < t)\n",
        "\n",
        "# Combine in one the predictions and actual positives values\n",
        "predict_positive & actual_positive\n",
        "# note: the way it combines the trues and falses is:\n",
        "# true and true is equal to true\n",
        "# false and true is equal to false\n",
        "# false and false is equal to false\n",
        "\n",
        "# note: the & operator it computes the element wise logical end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnBlUuuJfzo3",
        "outputId": "dc8e5684-8e0e-487d-cd20-f75ae9aee9f5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many predictions and actual positives are\n",
        "(predict_positive & actual_positive).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WlhLpvEgWAo",
        "outputId": "e0403995-66a9-4d9f-807c-9598782b6e27"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the true positive values in a variable\n",
        "tp = (predict_positive & actual_positive).sum()\n",
        "tp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgL9fF8diS9u",
        "outputId": "6ae9628f-12c2-4b76-b1fc-318277219ee4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the true negatives values in a variable\n",
        "tn = (predict_negative & actual_negative).sum()\n",
        "tn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0scjpMaiqtq",
        "outputId": "fc054e93-f705-4829-9d11-db3a61f61a80"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1202"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the false positive values in a variable\n",
        "fp = (predict_positive & actual_negative).sum()\n",
        "fp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1FIV-cjVIs",
        "outputId": "113fc72c-2d6e-445c-8bd4-0e29deaa5a9d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the false negatives values in a variable\n",
        "fn = (predict_negative & actual_positive).sum()\n",
        "fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULH5zeD7j_To",
        "outputId": "49e13a9b-0c71-4287-8d7b-e293e1c7a43e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create array with the confusion matrix\n",
        "confusion_matrix = np.array([\n",
        "    [tn, fp],\n",
        "    [fn, tp]\n",
        "])"
      ],
      "metadata": {
        "id": "msBRvCNkkbo3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the array with the confusion matrix\n",
        "confusion_matrix\n",
        "\n",
        "# below we can see the have more false negatives then false positives\n",
        "# false positives are the customers get a promotional email\n",
        "# even though they are not going to churn, so we actually lose some money\n",
        "# by giving them the discount so they are not going to churn but we given them discount\n",
        "\n",
        "# the false negative we don't send to the customers the email because they will leave\n",
        "# where are losing profit because we do not mange to retain these customers and they leave\n",
        "\n",
        "# we have different types of errors and the false negatives are more difficult to catch so\n",
        "# we have a lot more false negatives than false positives so have this situation now we know\n",
        "# what kind of errors the model makes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V2OYxWylYsV",
        "outputId": "7335b1f7-09ff-445c-8500-9e2604bfb38f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1202,  172],\n",
              "       [ 197,  289]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to normalize the confusion matrix above instead of having absolute numbers we can have relative \n",
        "# numbers, so we can have percents\n",
        "\n",
        "# Normalize the confusion matrix with percents\n",
        "(confusion_matrix / confusion_matrix.sum()).round(2)\n",
        "\n",
        "# 65% and 16% are correct predictions\n",
        "# 9% and 11% are incorrect predictions\n",
        "\n",
        "# we can conclude with our accuracy = 80% is 65% + 15% (not 16% because of the rouding)\n",
        "# this is how we get our accuracy of 80%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li5cnQCxlfOe",
        "outputId": "788493e8-0299-456c-9451-9507c280361d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65, 0.09],\n",
              "       [0.11, 0.16]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision and Recall:\n",
        "\n",
        "# Precision and recall are metrics for evaluating binary classification models\n",
        "\n",
        "# We can express accurcy as sum of true positive TP plus true negative TN\n",
        "# and we divide that by the total number of all the observations which is:\n",
        "# TP + TN + FP + FN\n",
        "\n",
        "# Express accuracy of our model\n",
        "(tp + tn) / (tp + tn + fp + fn)"
      ],
      "metadata": {
        "id": "F7WfLtBRoLKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9b641d-1a9a-42b8-8c9e-6d9c0014d460"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8016129032258065"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision:\n",
        "\n",
        "# Precision tell us how many positive predictions turned out to be correct\n",
        "# or more like not how many but fraction of correct positive predictions \n",
        "# so it means that we predict some customers as churning and then out of those\n",
        "# how many are identified correctly\n",
        "\n",
        "# Precision tell us among those customers that we predicted as churning what is\n",
        "# the fraction of correct predictions \n",
        "\n",
        "# Calculate the precision of our model\n",
        "p = tp / (tp + fp)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYvuDn3qrySY",
        "outputId": "8855d131-43a1-4f8e-f0ee-48518b428b3a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6268980477223427"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OyU70kjyRkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}