{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaaRXBua+MVe3tD12NT97w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-ML-Zoomcamp-Week-4/blob/main/ML_Zoomcamp_Week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goldsmiths University of London\n",
        "**Author....: Carlos Manuel de Oliveira Alves**<br>\n",
        "**Student..: cdeol003**<br>\n",
        "**Created..: 27/09/2022**"
      ],
      "metadata": {
        "id": "6gEcamMvoqD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sERKxvvdomPg"
      },
      "outputs": [],
      "source": [
        "# Import libraries for the project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import the library warnings to ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets train the model again first - to use its results later in this notebook\n",
        "\n",
        "# Import packages from Sklearn for the project\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "NU5InPEkuw-d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data import and preparation\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in string_columns:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "df.churn = (df.churn == 'yes').astype(int)"
      ],
      "metadata": {
        "id": "DwZLJNAjvYjo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the validation framework\n",
        "\n",
        "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
        "\n",
        "y_train = df_train.churn.values\n",
        "y_val = df_val.churn.values\n",
        "\n",
        "del df_train['churn']\n",
        "del df_val['churn']"
      ],
      "metadata": {
        "id": "_QfstrMiwCsY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of categorical and numerical variables\n",
        "\n",
        "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "               'phoneservice', 'multiplelines', 'internetservice',\n",
        "               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
        "               'techsupport', 'streamingtv', 'streamingmovies',\n",
        "               'contract', 'paperlessbilling', 'paymentmethod']\n",
        "\n",
        "numerical = ['tenure', 'monthlycharges', 'totalcharges']"
      ],
      "metadata": {
        "id": "Jhf2i3E5wTeO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv.fit(train_dict)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_train = dv.transform(train_dict)"
      ],
      "metadata": {
        "id": "s_T7YeKBwiPO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model logistic regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# For training the model we use the fit method\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hfgdUOuxggk",
        "outputId": "9233b2c6-5e74-438e-e15b-a351a4a53a79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create validation dictionary with categorical and numerical variables\n",
        "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our validation dictionary\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "# Apply our model on X validation and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]"
      ],
      "metadata": {
        "id": "n_VWjZV4yTkK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small subset from the dataframe\n",
        "small_subset = ['contract', 'tenure', 'totalcharges']\n",
        "\n",
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict_small = df_train[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv_small = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv_small.fit(train_dict_small)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_train = dv_small.transform(train_dict_small)\n",
        "\n",
        "# Create a model logistic regression\n",
        "model_small = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "model_small.fit(X_small_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQPuMETzwkJ",
        "outputId": "b392a9a9-3b89-40dd-d087-2629269186be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "val_dict_small = df_val[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_val = dv_small.transform(val_dict_small)\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred_small = model_small.predict_proba(X_small_val)[:, 1]"
      ],
      "metadata": {
        "id": "eDPSjIaXH7NA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy:\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Store the Y prediction has 50% or more\n",
        "churn = y_pred >= 0.5"
      ],
      "metadata": {
        "id": "EtUr8FW8IqD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}