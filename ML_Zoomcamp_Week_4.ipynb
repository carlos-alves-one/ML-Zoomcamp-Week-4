{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqWJPg1Zkz4/kqwgdm0egh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-ML-Zoomcamp-Week-4/blob/main/ML_Zoomcamp_Week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goldsmiths University of London\n",
        "**Author....: Carlos Manuel de Oliveira Alves**<br>\n",
        "**Student..: cdeol003**<br>\n",
        "**Created..: 27/09/2022**"
      ],
      "metadata": {
        "id": "6gEcamMvoqD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sERKxvvdomPg"
      },
      "outputs": [],
      "source": [
        "# Import libraries for the project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import the library warnings to ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets train the model again first - to use its results later in this notebook\n",
        "\n",
        "# Import packages from Sklearn for the project\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "NU5InPEkuw-d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data import and preparation\n",
        "\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "for col in string_columns:\n",
        "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
        "\n",
        "df.churn = (df.churn == 'yes').astype(int)"
      ],
      "metadata": {
        "id": "DwZLJNAjvYjo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the validation framework\n",
        "\n",
        "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
        "\n",
        "y_train = df_train.churn.values\n",
        "y_val = df_val.churn.values\n",
        "\n",
        "del df_train['churn']\n",
        "del df_val['churn']"
      ],
      "metadata": {
        "id": "_QfstrMiwCsY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of categorical and numerical variables\n",
        "\n",
        "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "               'phoneservice', 'multiplelines', 'internetservice',\n",
        "               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
        "               'techsupport', 'streamingtv', 'streamingmovies',\n",
        "               'contract', 'paperlessbilling', 'paymentmethod']\n",
        "\n",
        "numerical = ['tenure', 'monthlycharges', 'totalcharges']"
      ],
      "metadata": {
        "id": "Jhf2i3E5wTeO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv.fit(train_dict)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_train = dv.transform(train_dict)"
      ],
      "metadata": {
        "id": "s_T7YeKBwiPO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model logistic regression\n",
        "model = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# For training the model we use the fit method\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hfgdUOuxggk",
        "outputId": "765a6c93-39f6-45ec-a83d-cf1e713ac239"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create validation dictionary with categorical and numerical variables\n",
        "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our validation dictionary\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "# Apply our model on X validation and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]"
      ],
      "metadata": {
        "id": "n_VWjZV4yTkK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small subset from the dataframe\n",
        "small_subset = ['contract', 'tenure', 'totalcharges']\n",
        "\n",
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "train_dict_small = df_train[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Create a new instance of the DictVectorizer class without sparse\n",
        "dv_small = DictVectorizer(sparse=False)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "dv_small.fit(train_dict_small)\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_train = dv_small.transform(train_dict_small)\n",
        "\n",
        "# Create a model logistic regression\n",
        "model_small = LogisticRegression(solver='liblinear', random_state=1)\n",
        "\n",
        "# Use the method fit and first we train our DictVectorizer\n",
        "model_small.fit(X_small_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQPuMETzwkJ",
        "outputId": "f555925c-d1b5-4d53-dc85-3f9a43c87112"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the data into a dictionary and we want each row to turn into a dictionary \n",
        "val_dict_small = df_val[small_subset].to_dict(orient='records')\n",
        "\n",
        "# Use the function transform with our DictVectorizer\n",
        "X_small_val = dv_small.transform(val_dict_small)\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred_small = model_small.predict_proba(X_small_val)[:, 1]"
      ],
      "metadata": {
        "id": "eDPSjIaXH7NA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy:\n",
        "\n",
        "# Apply our model on Y predition and use the first column\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Store the Y prediction has 50% or more\n",
        "churn = y_pred >= 0.5\n",
        "\n",
        "# Calculate the percentange of the churn using the mean function\n",
        "(churn == y_val).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtUr8FW8IqD2",
        "outputId": "f4e8eb91-0b71-408a-ad68-eaf89f055f59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8016129032258065"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy and dummy model:\n",
        "\n",
        "# Evaluate the model on different thresholds\n",
        "# Check the accuracy of dummy baselines\n",
        "\n",
        "# Check how many customers we have with Y validation dataset\n",
        "len(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJzIUEz6JuGw",
        "outputId": "3d52e424-f3b4-4a9d-e706-d57f51d08f65"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1860"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 1.860 customers and for all this customers we will make a prediction\n",
        "# each customer we assign a score and then we make a decision\n",
        "# some of this decisions are correct and some of this decisions are incorrect\n",
        "\n",
        "# Check how many decisions are correct\n",
        "(y_val == churn).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl5KmgmmKk70",
        "outputId": "fafac606-a90f-4f63-924c-c8b2c22ea5e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1491"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so have 1.491 customers with the correct decision\n",
        "\n",
        "# some of our decisions are not correct and we calculate doing:\n",
        "# total of correct decisions or predictions divide by the total of customers\n",
        "# in our case is 80%"
      ],
      "metadata": {
        "id": "6BDALL1AL9oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(round((1491 / 1860) * 100)) + '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9YU7rHhM7jL",
        "outputId": "6e255abb-46e6-4747-fb84-f8aaa90f4356"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function linspace to generate numbers from 0 to 1 with size of the array 21 elements\n",
        "thresholds = np.linspace(0, 1, 21)\n",
        "thresholds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zG7UbDJNM4d",
        "outputId": "fbebade8-f6c0-4f4b-a937-484c8dace358"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For eah of the values above we can treat as a threshold\n",
        "for t in thresholds:\n",
        "\n",
        "  # Store the Y prediction we use t threshold list intead of has 50% or more\n",
        "  # churn = y_pred >= 0.5 <-- THIS LINE OF CODE IT WAS BEFORE\n",
        "  # NEW LINE OF CODE:\n",
        "  churn_decision = (y_pred >= t)\n",
        "\n",
        "  # Check how many decisions are correct\n",
        "  (y_val == churn_decision).mean()"
      ],
      "metadata": {
        "id": "eIUJj47VNzAZ"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}